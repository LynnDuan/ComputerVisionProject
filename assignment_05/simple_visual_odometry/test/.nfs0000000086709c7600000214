////
//// Created by sicong on 08/11/18.
////
//
//#include <iostream>
//#include <fstream>
//#include <list>
//#include <vector>
//#include <chrono>
//using namespace std;
//
//
//#include <opencv2/core/core.hpp>
//#include <opencv2/highgui/highgui.hpp>
//#include <opencv2/features2d/features2d.hpp>
//#include <opencv2/video/tracking.hpp>
//
//using namespace cv;
//int main( int argc, char** argv )
//{
//
//    if ( argc != 3 )
//    {
//        cout<<"usage: feature_extraction img1 img2"<<endl;
//        return 1;
//    }
//    //-- Read two images
//    Mat img_1 = imread ( argv[1], CV_LOAD_IMAGE_COLOR );
//    Mat img_2 = imread ( argv[2], CV_LOAD_IMAGE_COLOR );
//
//    list< cv::Point2f > keypoints;
//    vector<cv::KeyPoint> kps;
//
//    std::string detectorType = "Feature2D.BRISK";
//    Ptr<FeatureDetector>detector = Algorithm::create<FeatureDetector>(detectorType);
//	detector->set("thres", 100);
//
//
//    detector->detect( img_1, kps );
//    for ( auto kp:kps )
//        keypoints.push_back( kp.pt );
//
//    vector<cv::Point2f> next_keypoints;
//    vector<cv::Point2f> prev_keypoints;
//    for ( auto kp:keypoints )
//        prev_keypoints.push_back(kp);
//    vector<unsigned char> status;
//    vector<float> error;
//    chrono::steady_clock::time_point t1 = chrono::steady_clock::now();
//    cv::calcOpticalFlowPyrLK( img_1, img_2, prev_keypoints, next_keypoints, status, error );
//    chrono::steady_clock::time_point t2 = chrono::steady_clock::now();
//    chrono::duration<double> time_used = chrono::duration_cast<chrono::duration<double>>( t2-t1 );
//    cout<<"LK Flow use time："<<time_used.count()<<" seconds."<<endl;
//
//    // visualize all  keypoints
//    hconcat(img_1,img_2,img_1);
//    for ( int i=0; i< prev_keypoints.size() ;i++)
//    {
//        cout<<(int)status[i]<<endl;
//        if(status[i] == 1)
//        {
//            Point pt;
//            pt.x =  next_keypoints[i].x + img_2.size[1];
//            pt.y =  next_keypoints[i].y;
//
//            line(img_1, prev_keypoints[i], pt, cv::Scalar(0,255,255));
//        }
//    }
//
//    cv::imshow("klt tracker", img_1);
//    cv::waitKey(0);
//
//    return 0;
//}


//
// Created by sicong on 08/11/18.
//

#include <iostream>
#include <fstream>
#include <list>
#include <vector>
#include <ctime>
#include <chrono>
#include <unordered_set>
#include <math.h>
using namespace std;


#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/features2d/features2d.hpp>
#include <opencv2/video/tracking.hpp>

using namespace cv;

#include <opencv2/calib3d/calib3d.hpp>
#include <opencv2/imgproc/imgproc.hpp>

cv::Matx33d normaliztionmatrix(cv::Mat img){
    Matx33d M;
    cv::Size s = img.size();
    int rows = s.height;
    int cols = s.width;
    M(0,0) = 2.0 / cols;
    M(0,1) = 0.0;
    M(0,2) = -1.0;
    M(1,0) = 0.0;
    M(1,1) = 2.0 / rows;
    M(1,2) = -1.0;
    M(2,0) = 0.0;
    M(2,1) = 0.0;
    M(2,2) = 1.0;
    return M;
}

cv::Matx33d Findfundamental(vector<cv::Point2f> prev_subset,vector<cv::Point2f> next_subset){
    int num = prev_subset.size();
    cv::Mat A(num,9,CV_64FC1, Scalar(1));
    for (int i = 0; i < num; i++){
        A.at<double>(i,0) = prev_subset[i].x * next_subset[i].x;
        A.at<double>(i,1) = prev_subset[i].x * next_subset[i].y;
        A.at<double>(i,2) = prev_subset[i].x;
        A.at<double>(i,3) = prev_subset[i].y * next_subset[i].x;
        A.at<double>(i,4) = prev_subset[i].y * next_subset[i].y;
        A.at<double>(i,5) = prev_subset[i].y;
        A.at<double>(i,6) = next_subset[i].x;
        A.at<double>(i,7) = next_subset[i].y;
        A.at<double>(i,8) = 1.0;   
    }
    cv::SVD svd(A);
    cv::Mat VT(svd.vt);
    cv::Mat Fund(VT.row(VT.rows-1));
    
    cv::Matx33d fund;
    for(int i = 0;i < 3; i++){
        for (int j = 0; j < 3; j++){
            fund(i,j) = Fund.at<double>(3*i+j);
        }
    }

    cv::SVD svd1(fund);
    cv::Mat U1(svd1.u);
    cv::Mat W1(svd1.w);
    cv::Mat VT1(svd1.vt);
    W1.at<double>(2) = 0.0;
    cv::Mat w1(3,3,CV_64FC1, Scalar(0));
    for (int i = 0; i < 3; i++){
        w1.at<double>(i,i) = W1.at<double>(i);
    }

    cv::Matx33d F = (cv::Mat)(U1 * w1 * VT1);

    return F;
}
bool checkinlier(cv::Point2f prev_keypoint,cv::Point2f next_keypoint,cv::Matx33d Fcandidate,double d){
    cv::Matx13d Prev;
    Prev(0) = prev_keypoint.x;
    Prev(1) = prev_keypoint.y;
    Prev(2) = 1.0;
    cv::Matx31d Next;
    Next(0) = next_keypoint.x;
    Next(1) = next_keypoint.y;
    Next(2) = 1.0;

    double tmp = fabs((Prev * Fcandidate * Next)(0));
    if (tmp <= d){
        return true;
    }
    else{
        return false;
    }    
}

// cv::Matx33d Findessential(cv::Matx33d F, cv::Matx33d K1, cv::Matx33d K2){
//     cv::Matx33d E;
//     E = K1.t() * F * K2;
//     return E;
// }

// cv::Matx33d 


 float distancePointLine(const cv::Point2f point, const cv::Vec<double,3>& line)
 {
   //Line is given as a*x + b*y + c = 0
   return std::fabs(line(0)*point.x + line(1)*point.y + line(2))
       / std::sqrt(line(0)*line(0)+line(1)*line(1));
 }

void drawEpipolarLines(const std::string& title, const cv::Matx33d F,
                 cv::Mat& img1, cv::Mat& img2,
                 std::vector<cv::Point2f> points1,
                 std::vector<cv::Point2f> points2,
                 const float inlierDistance = -1)
 {
    CV_Assert(img1.size() == img2.size() && img1.type() == img2.type());
    cv::Mat outImg1(img1.rows, img1.cols*2, CV_8UC1);
    cv::cvtColor(img1, outImg1, CV_BGR2GRAY);
    cv::Mat outImg2(img1.rows, img1.cols*2, CV_8UC1);
    cv::cvtColor(img2, outImg2, CV_BGR2GRAY);
    std::vector<cv::Vec3f> epilines1, epilines2;
    cv::computeCorrespondEpilines(points1, 1, F, epilines1); //Index starts with 1
    cv::computeCorrespondEpilines(points2, 2, F, epilines2);

    for(size_t i=0; i<points1.size(); i++){
        cv::Scalar color(255);
        int temp1 = img1.cols;
        int temp2 = img2.cols;
        cv::line(outImg1,
        cv::Point(0,-epilines1[i][2]/epilines1[i][1]),
        cv::Point(temp1,-(epilines1[i][2]+epilines1[i][0]*temp1)/epilines1[i][1]),
        color);
        cv::circle(outImg1, points1[i], 3, color, -1, CV_AA);

        cv::line(outImg2,
        cv::Point(0,-epilines2[i][2]/epilines2[i][1]),
        cv::Point(temp2,-(epilines2[i][2]+epilines2[i][0]*temp2)/epilines2[i][1]),
        color);
        cv::circle(outImg2, points2[i], 3, color, -1, CV_AA);
    }
    Mat HImg;
    hconcat(outImg1, outImg2, HImg);

    namedWindow(title, WINDOW_AUTOSIZE );
    cv::imshow(title, HImg);
    cv::waitKey(0);
 }
 


int main( int argc, char** argv )
{

    srand ( time(NULL) );

    if ( argc != 3 )
    {
        cout<<"usage: feature_extraction img1 img2"<<endl;
        return 1;
    }
    //-- Read two images
    Mat img_1 = imread ( argv[1], CV_LOAD_IMAGE_COLOR );
    Mat img_2 = imread ( argv[2], CV_LOAD_IMAGE_COLOR );

    list< cv::Point2f > keypoints;
    vector<cv::KeyPoint> kps;

    std::string detectorType = "Feature2D.BRISK";
    Ptr<FeatureDetector>detector = Algorithm::create<FeatureDetector>(detectorType);
    detector->set("thres", 100);


    detector->detect( img_1, kps );
    for ( auto kp:kps )
        keypoints.push_back( kp.pt );

    vector<cv::Point2f> next_keypoints;
    vector<cv::Point2f> prev_keypoints;
    for ( auto kp:keypoints )
        prev_keypoints.push_back(kp);
    vector<unsigned char> status;
    vector<float> error;
    chrono::steady_clock::time_point t1 = chrono::steady_clock::now();
    cv::calcOpticalFlowPyrLK( img_1, img_2, prev_keypoints, next_keypoints, status, error );
    chrono::steady_clock::time_point t2 = chrono::steady_clock::now();
    chrono::duration<double> time_used = chrono::duration_cast<chrono::duration<double>>( t2-t1 );
    cout<<"LK Flow use time："<<time_used.count()<<" seconds."<<endl;

    vector<cv::Point2f> kps_prev,kps_next;
    vector<cv::Point2f> KPS_prev,KPS_next; // Draw a figure to show epipolar constraint
    kps_prev.clear();
    kps_next.clear();
    for(size_t i=0;i<prev_keypoints.size();i++)
    {
        if(status[i] == 1)
        {
            kps_prev.push_back(prev_keypoints[i]);
            kps_next.push_back(next_keypoints[i]);
            KPS_prev.push_back(prev_keypoints[i]);
            KPS_next.push_back(next_keypoints[i]);
        }
    }
    //get normaliation matrix
    Matx33d Norm = normaliztionmatrix(img_1);
    for (size_t i = 0; i < kps_prev.size(); i++){
        kps_prev[i].x = kps_prev[i].x * Norm(0,0) - 1;
        kps_prev[i].y = kps_prev[i].y * Norm(1,1) - 1;
        kps_next[i].x = kps_next[i].x * Norm(0,0) - 1;
        kps_next[i].y = kps_next[i].y * Norm(1,1) - 1;
    }

    double p = 0.9;
    double d = 0.05f;
    double e = 0.2;

    int niter = 500;
    Mat Fundamental;
    cv::Matx33d F,Fcandidate;
    int bestinliers = -1;
    vector<cv::Point2f> prev_subset,next_subset;
    int matches = kps_prev.size();
    prev_subset.clear();
    next_subset.clear();
    cout << "size: " << KPS_prev.size() << endl;

    for(int i=0;i<niter;i++){
        // step1: randomly sample 8 matches for 8pt algorithm
        unordered_set<int> rand_util;
        while(rand_util.size()<8)
        {
            int randi = rand() % matches;
            rand_util.insert(randi);
        }
        vector<int> random_indices (rand_util.begin(),rand_util.end());
        for(size_t j = 0;j<rand_util.size();j++){
            prev_subset.push_back(kps_prev[random_indices[j]]);
            next_subset.push_back(kps_next[random_indices[j]]);
        }
        // step2: perform 8pt algorithm, get candidate F
        Fcandidate = Findfundamental(prev_subset,next_subset);
        // step3: Evaluate inliers, decide if we need to update the best solution
        int inliers = 0;
        for(size_t j=0;j<kps_prev.size();j++){
            if(checkinlier(kps_prev[j],kps_next[j],Fcandidate,d))
                inliers++;
        }
        if(inliers > bestinliers)
        {
            F = Fcandidate;
            bestinliers = inliers;
            cout << "bestinliers: " << bestinliers << endl;
        }
        prev_subset.clear();
        next_subset.clear();
    }

    // step4: After we finish all the iterations, use the inliers of the best model to compute Fundamental matrix again.

    for(size_t j=0;j<kps_prev.size();j++){
        if(checkinlier(kps_prev[j],kps_next[j],F,d))
        {
            prev_subset.push_back(kps_prev[j]);
            next_subset.push_back(kps_next[j]);
        }

    }
    F = Findfundamental(prev_subset,next_subset);
    F = Norm.t() * F * Norm;

    cout<<"Fundamental matrix is \n"<<F<<endl;

    drawEpipolarLines("epipolar line", F, img_1, img_2, KPS_prev, KPS_next, -1);

    return 0;
}



